import pandas as pd

# Load the dataset
data = pd.read_csv('/content/kc_house_data.csv')
# Fill missing values
numeric_columns = data.select_dtypes(include=['number']).columns
data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())

# Split features and target variable
X = data.drop('price', axis=1)

# Convert 'date' column to datetime objects if needed
X['date'] = pd.to_datetime(X['date'])  

# Extract numerical features for scaling, excluding 'date' and other non-numerical columns
numerical_features = X.select_dtypes(include=['number']).columns
X_numerical = X[numerical_features]

y = data['price']

# Normalize numerical features
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_numerical)  # Scale only numerical features

# Now you can proceed with the rest of your code
# ... (rest of your code remains unchanged)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
from sklearn.linear_model import LinearRegression

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
from sklearn.tree import DecisionTreeRegressor

tree_model = DecisionTreeRegressor()
tree_model.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error

# Predict
y_pred_lr = lr_model.predict(X_test)
y_pred_tree = tree_model.predict(X_test)

# Evaluate Linear Regression
mse_lr = mean_squared_error(y_test, y_pred_lr)

# Evaluate Decision Tree
mse_tree = mean_squared_error(y_test, y_pred_tree)

print("Linear Regression MSE:", mse_lr)
print("Decision Tree MSE:", mse_tree)